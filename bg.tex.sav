\section{Solving Word Substitution Ciphers}
\label{wsc}
Recently, there has been an increasing interest in decipherment works \cite{ravi-knight:2011:zodic,Ravi:2008:ADP:1613715.1613819}. While letter substitution ciphers can be solved easily, nobody has been able to solve a word substitution cipher. Nonetheless, with the ability to solve word substitution ciphers, one can possibly find translations for unknown word or even build a full vocabulary machine translation system from monolingual corpora.

As shown in figure \ref{cipher}, a word substitution cipher is generated by replacing each word in a natural language (plaintext) sequence with a cipher token according to a substitution table. The mapping in the table is deterministic -- each plaintext word type is only encoded with one unique cipher token. Solving a word substitution cipher is to recover the original plaintext from the cipher text without knowing the substitution table.

\begin{figure}[!ht]
  \centering

  \includegraphics[width=3in]{cipher}
  \caption{Word Substitution Cipher: Encoding, Decipherment, and Decoding}
\label{cipher}

\end{figure}

How can we solve a word substitution cipher? The approach is similar to those taken by cryptanalysts who try to recover keys that can convert encrypted texts to readable texts. In the scenario of translation, we try to learn a translation table that can convert source languages to sensible target languages. Suppose we observe a large amount of foreign strings $f$ and want to decipher it into English $e$. In \cite{ravi-knight:2011}, Ravi and Knight assume that the foreign strings f are generated in the following way:

\begin{itemize}
\item (1) Generate English plain text sequence $e = e_{1},e_{2}...e_{n}$ with probability P(e).
\item (2) Replace each English plain text token $e_{i}$ with a foreign token $f_{i}$ with probability $P(f_{i}|e_{i})$.
\end{itemize}
%
Based on the above generative story, the probability of the foreign strings f can be written as:

\begin{equation}
\label{obj_f}
P(f)_\theta =  \sum_{c} P(e) \cdot \prod_{i}^{n}  P_{\theta}(f_{i}|e_{i})
\end{equation}
%

By applying maximum likelihood training, the above equation can be used as an objective function for solving a word substitution cipher. $P(e)$ is given by an n-gram language model, which can be trained using a large amount of monolingual texts. The rest of the task is to manipulate word translation probabilities $P_{\theta}(f_{i}|e_{i})$ so that the probability of the observed texts $P(f)_\theta$ is maximized.


Theoretically, we can directly apply EM proposed in  \cite{knight-EtAl:2006} or Bayesian Decipherment in \cite{ravi-knight:2011:zodic} to solve the problem. However, unlike letter substitution ciphers, word substitution ciphers pose much greater challenges to algorithm scalability. To solve a word substitution cipher, the EM algorithm has a computational complexity of $O(V^{2}\cdot N\cdot R)$ and the complexity of Bayesian method is $O(N\cdot R\cdot V)$, where V is the size of plain text vocabulary, N is the length of cipher text, and R is the number of iterations. In the world of word substitution ciphers, both V and N are very large, making the above approaches impractical. \cite{ravi-knight:2011} proposed several modifications to the existing algorithms to make them scalable. However, the modifications lead to significant loss in deciphering accuracy and is still far less efficient to handle very large scale ciphers. 

To address the above problems, we propose two new improvements to In this paper, we adopt a different inference algorithm--slice sampling \cite{Neal00slicesampling}. The new algorithm does not only scale well but also improves deciphering accuracy by a large margin.


``Decoding'' refers to the process of converting cipher text to plain text given a substitution table and a language model.
We use Viterbi algorithm to find the highest scored English sequence according the following formula:
\begin{equation}
\argmax_e P(e) \cdot \prod_{i}^{n}  P_{\theta}(c_{i}|e_{i})
\end{equation}